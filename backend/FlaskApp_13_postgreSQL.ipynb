{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a8dd616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  15 of 15 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: ['ADANIPORTS.NS', 'APOLLOHOSP.NS', 'ASIANPAINT.NS', 'AXISBANK.NS', 'BAJAJ-AUTO.NS', 'BAJFINANCE.NS', 'BAJAJFINSV.NS', 'BPCL.NS', 'BHARTIARTL.NS', 'BRITANNIA.NS', 'CIPLA.NS', 'COALINDIA.NS', 'DIVISLAB.NS', 'DRREDDY.NS', 'EICHERMOT.NS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  15 of 15 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: ['GRASIM.NS', 'HCLTECH.NS', 'HDFCBANK.NS', 'HDFCLIFE.NS', 'HEROMOTOCO.NS', 'HINDALCO.NS', 'HINDUNILVR.NS', 'ICICIBANK.NS', 'ITC.NS', 'INDUSINDBK.NS', 'INFY.NS', 'JSWSTEEL.NS', 'KOTAKBANK.NS', 'LT.NS', 'M&M.NS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  15 of 15 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: ['MARUTI.NS', 'NESTLEIND.NS', 'NTPC.NS', 'ONGC.NS', 'POWERGRID.NS', 'RELIANCE.NS', 'SBILIFE.NS', 'SBIN.NS', 'SUNPHARMA.NS', 'TATAMOTORS.NS', 'TATASTEEL.NS', 'TCS.NS', 'TECHM.NS', 'TITAN.NS', 'ULTRACEMCO.NS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: ['UPL.NS', 'WIPRO.NS']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from app import app, db, bcrypt\n",
    "from models import User, Stock, Portfolio\n",
    "from flask import jsonify, request\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import time\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Nifty 50 company symbols (Yahoo Finance format)\n",
    "companyNamesArray = [\n",
    "    'ADANIPORTS.NS', 'APOLLOHOSP.NS', 'ASIANPAINT.NS', 'AXISBANK.NS', 'BAJAJ-AUTO.NS', 'BAJFINANCE.NS', 'BAJAJFINSV.NS',\n",
    "    'BPCL.NS', 'BHARTIARTL.NS', 'BRITANNIA.NS', 'CIPLA.NS', 'COALINDIA.NS', 'DIVISLAB.NS', 'DRREDDY.NS', 'EICHERMOT.NS',\n",
    "    'GRASIM.NS', 'HCLTECH.NS', 'HDFCBANK.NS', 'HDFCLIFE.NS', 'HEROMOTOCO.NS', 'HINDALCO.NS', 'HINDUNILVR.NS',\n",
    "    'ICICIBANK.NS', 'ITC.NS', 'INDUSINDBK.NS', 'INFY.NS', 'JSWSTEEL.NS', 'KOTAKBANK.NS', 'LT.NS', 'M&M.NS',\n",
    "    'MARUTI.NS', 'NESTLEIND.NS', 'NTPC.NS', 'ONGC.NS', 'POWERGRID.NS', 'RELIANCE.NS', 'SBILIFE.NS', 'SBIN.NS',\n",
    "    'SUNPHARMA.NS', 'TATAMOTORS.NS', 'TATASTEEL.NS', 'TCS.NS', 'TECHM.NS', 'TITAN.NS', 'ULTRACEMCO.NS', 'UPL.NS', 'WIPRO.NS'\n",
    "]\n",
    "\n",
    "all_data = []\n",
    "batch_size = 15\n",
    "\n",
    "for i in range(0, len(companyNamesArray), batch_size):\n",
    "    batch = companyNamesArray[i:i+batch_size]\n",
    "    tickers = \" \".join(batch)\n",
    "    try:\n",
    "        ms = yf.Tickers(tickers)\n",
    "        data = ms.history(period=\"max\")\n",
    "        all_data.append(data)\n",
    "        print(f\"Downloaded: {batch}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed batch {batch}: {e}\")\n",
    "    time.sleep(65)  # Wait 10 seconds between batches\n",
    "\n",
    "# Combine all_data into a single DataFrame\n",
    "stockData_22 = pd.concat(all_data)\n",
    "stockData_22 = stockData_22.loc[:, (['Close','Volume','Dividends','Stock Splits'], companyNamesArray)]\n",
    "stockData_22.columns = stockData_22.columns.map(lambda x: f\"{x[0]}_{x[1]}\")\n",
    "metrics = ['Close','Volume', 'Dividends', 'Stock Splits']\n",
    "\n",
    "# Prepare the value_vars dictionary dynamically\n",
    "value_vars = {}\n",
    "for company in companyNamesArray:\n",
    "    for metric in metrics:\n",
    "        column_name = f\"{metric}_{company}\"\n",
    "        if column_name in stockData_22.columns:\n",
    "            value_vars[column_name] = (company, metric)\n",
    "            \n",
    "stockData_22 = stockData_22.reset_index()  # Add this line before melt\n",
    "df_long = stockData_22.melt(\n",
    "    id_vars=[\"Date\"], \n",
    "    var_name='variable',\n",
    "    value_name='value',\n",
    "    value_vars=value_vars\n",
    ")\n",
    "df_long[['metric','company']] = df_long['variable'].str.split('_', expand=True)\n",
    "df_long = df_long.drop(columns='variable')\n",
    "new_order = ['Date','company','metric','value']\n",
    "df_long = df_long[new_order]\n",
    "\n",
    "# Create Metrics Table\n",
    "metrics_df = df_long[['metric']].drop_duplicates().reset_index(drop=True)\n",
    "metrics_df['Metric_ID'] = metrics_df.index + 1\n",
    "metrics_df = metrics_df[['Metric_ID', 'metric']]\n",
    "\n",
    "# Create Companies Table\n",
    "companies_df = df_long[['company']].drop_duplicates().reset_index(drop=True)\n",
    "companies_df['Company_ID'] = companies_df.index + 1\n",
    "companies_df = companies_df[['Company_ID', 'company']]\n",
    "\n",
    "# Create Data Table\n",
    "data_df = df_long.merge(companies_df, on='company').merge(metrics_df, on='metric')\n",
    "data_df = data_df[['Date', 'Company_ID', 'Metric_ID', 'value']]\n",
    "\n",
    "# --- Connect to PostgreSQL database (Docker) ---\n",
    "# Example: postgresql://postgres:password@localhost:5432/your_db\n",
    "load_dotenv()\n",
    "#pg_url = f\"postgresql://{os.getenv('POSTGRES_USER')}:{os.getenv('POSTGRES_PASSWORD')}@localhost:5432/{os.getenv('POSTGRES_DB')}\"\n",
    "#pg_url = \"postgresql://postgres:yourpassword@localhost:5432/your_db\"\n",
    "#engine = create_engine(pg_url)\n",
    "\n",
    "# Connect to the default 'postgres' database\n",
    "engine = create_engine(f\"postgresql://{os.getenv('POSTGRES_USER')}:{os.getenv('POSTGRES_PASSWORD')}@localhost:5432/postgres\")\n",
    "with engine.connect() as conn:\n",
    "    conn.execution_options(isolation_level=\"AUTOCOMMIT\").execute(text(f\"CREATE DATABASE {os.getenv('POSTGRES_DB')}\"))\n",
    "\n",
    "pg_url = f\"postgresql://{os.getenv('POSTGRES_USER')}:{os.getenv('POSTGRES_PASSWORD')}@localhost:5432/{os.getenv('POSTGRES_DB')}\"\n",
    "engine = create_engine(pg_url)\n",
    "\n",
    "# Write the dataframes to SQL tables\n",
    "metrics_df.to_sql('Metrics', engine, if_exists='replace', index=False)\n",
    "companies_df.to_sql('Companies', engine, if_exists='replace', index=False)\n",
    "data_df.to_sql('Data', engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Data written to PostgreSQL database.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a27f95fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mall_data\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_data' is not defined"
     ]
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac674d98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stockData_22' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstockData_22\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stockData_22' is not defined"
     ]
    }
   ],
   "source": [
    "stockData_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4655d468",
   "metadata": {},
   "outputs": [
    {
     "ename": "ObjectNotExecutableError",
     "evalue": "Not an executable object: 'CREATE DATABASE investments_db'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/my_project_dir3/investment_app/backend/investmentapp/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1412\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[43mstatement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_on_connection\u001b[49m\n\u001b[1;32m   1413\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute '_execute_on_connection'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mObjectNotExecutableError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m engine \u001b[38;5;241m=\u001b[39m create_engine(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpostgresql://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOSTGRES_USER\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOSTGRES_PASSWORD\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m@localhost:5432/postgres\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mconnect() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[0;32m---> 37\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43misolation_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAUTOCOMMIT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCREATE DATABASE \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOSTGRES_DB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m pg_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpostgresql://postgres:yourpassword@localhost:5432/your_db\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m engine \u001b[38;5;241m=\u001b[39m create_engine(pg_url)\n",
      "File \u001b[0;32m~/my_project_dir3/investment_app/backend/investmentapp/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1414\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1412\u001b[0m     meth \u001b[38;5;241m=\u001b[39m statement\u001b[38;5;241m.\u001b[39m_execute_on_connection\n\u001b[1;32m   1413\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 1414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m meth(\n\u001b[1;32m   1417\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1418\u001b[0m         distilled_parameters,\n\u001b[1;32m   1419\u001b[0m         execution_options \u001b[38;5;129;01mor\u001b[39;00m NO_OPTIONS,\n\u001b[1;32m   1420\u001b[0m     )\n",
      "\u001b[0;31mObjectNotExecutableError\u001b[0m: Not an executable object: 'CREATE DATABASE investments_db'"
     ]
    }
   ],
   "source": [
    "            \n",
    "stockData_22 = stockData_22.reset_index()  # Add this line before melt\n",
    "df_long = stockData_22.melt(\n",
    "    id_vars=[\"Date\"], \n",
    "    var_name='variable',\n",
    "    value_name='value',\n",
    "    value_vars=value_vars\n",
    ")\n",
    "df_long[['metric','company']] = df_long['variable'].str.split('_', expand=True)\n",
    "df_long = df_long.drop(columns='variable')\n",
    "new_order = ['Date','company','metric','value']\n",
    "df_long = df_long[new_order]\n",
    "\n",
    "# Create Metrics Table\n",
    "metrics_df = df_long[['metric']].drop_duplicates().reset_index(drop=True)\n",
    "metrics_df['Metric_ID'] = metrics_df.index + 1\n",
    "metrics_df = metrics_df[['Metric_ID', 'metric']]\n",
    "\n",
    "# Create Companies Table\n",
    "companies_df = df_long[['company']].drop_duplicates().reset_index(drop=True)\n",
    "companies_df['Company_ID'] = companies_df.index + 1\n",
    "companies_df = companies_df[['Company_ID', 'company']]\n",
    "\n",
    "# Create Data Table\n",
    "data_df = df_long.merge(companies_df, on='company').merge(metrics_df, on='metric')\n",
    "data_df = data_df[['Date', 'Company_ID', 'Metric_ID', 'value']]\n",
    "\n",
    "# --- Connect to PostgreSQL database (Docker) ---\n",
    "# Example: postgresql://postgres:password@localhost:5432/your_db\n",
    "load_dotenv()\n",
    "#pg_url = f\"postgresql://{os.getenv('POSTGRES_USER')}:{os.getenv('POSTGRES_PASSWORD')}@localhost:5432/{os.getenv('POSTGRES_DB')}\"\n",
    "#pg_url = \"postgresql://postgres:yourpassword@localhost:5432/your_db\"\n",
    "#engine = create_engine(pg_url)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13c73e36",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msqlalchemy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m text\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Connect to the default 'postgres' database\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_engine\u001b[49m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpostgresql://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOSTGRES_USER\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOSTGRES_PASSWORD\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m@localhost:5432/postgres\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mconnect() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m      5\u001b[0m     conn\u001b[38;5;241m.\u001b[39mexecution_options(isolation_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUTOCOMMIT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexecute(text(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCREATE DATABASE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOSTGRES_DB\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_engine' is not defined"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "# Connect to the default 'postgres' database\n",
    "engine = create_engine(f\"postgresql://{os.getenv('POSTGRES_USER')}:{os.getenv('POSTGRES_PASSWORD')}@localhost:5432/postgres\")\n",
    "with engine.connect() as conn:\n",
    "    conn.execution_options(isolation_level=\"AUTOCOMMIT\").execute(text(f\"CREATE DATABASE {os.getenv('POSTGRES_DB')}\"))\n",
    "\n",
    "pg_url = f\"postgresql://{os.getenv('POSTGRES_USER')}:{os.getenv('POSTGRES_PASSWORD')}@localhost:5432/{os.getenv('POSTGRES_DB')}\"\n",
    "engine = create_engine(pg_url)\n",
    "\n",
    "# Write the dataframes to SQL tables\n",
    "metrics_df.to_sql('Metrics', engine, if_exists='replace', index=False)\n",
    "companies_df.to_sql('Companies', engine, if_exists='replace', index=False)\n",
    "data_df.to_sql('Data', engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Data written to PostgreSQL database.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39acb91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  15 of 15 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: ['ADANIPORTS.NS', 'APOLLOHOSP.NS', 'ASIANPAINT.NS', 'AXISBANK.NS', 'BAJAJ-AUTO.NS', 'BAJFINANCE.NS', 'BAJAJFINSV.NS', 'BPCL.NS', 'BHARTIARTL.NS', 'BRITANNIA.NS', 'CIPLA.NS', 'COALINDIA.NS', 'DIVISLAB.NS', 'DRREDDY.NS', 'EICHERMOT.NS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  15 of 15 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: ['GRASIM.NS', 'HCLTECH.NS', 'HDFCBANK.NS', 'HDFCLIFE.NS', 'HEROMOTOCO.NS', 'HINDALCO.NS', 'HINDUNILVR.NS', 'ICICIBANK.NS', 'ITC.NS', 'INDUSINDBK.NS', 'INFY.NS', 'JSWSTEEL.NS', 'KOTAKBANK.NS', 'LT.NS', 'M&M.NS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  15 of 15 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: ['MARUTI.NS', 'NESTLEIND.NS', 'NTPC.NS', 'ONGC.NS', 'POWERGRID.NS', 'RELIANCE.NS', 'SBILIFE.NS', 'SBIN.NS', 'SUNPHARMA.NS', 'TATAMOTORS.NS', 'TATASTEEL.NS', 'TCS.NS', 'TECHM.NS', 'TITAN.NS', 'ULTRACEMCO.NS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: ['UPL.NS', 'WIPRO.NS']\n",
      "Note: (psycopg2.errors.DuplicateDatabase) database \"investments_db_nifty50\" already exists\n",
      "\n",
      "[SQL: CREATE DATABASE investments_db_nifty50]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "Processed ADANIPORTS.NS - Close\n",
      "Processed APOLLOHOSP.NS - Close\n",
      "Processed ASIANPAINT.NS - Close\n",
      "Processed AXISBANK.NS - Close\n",
      "Processed BAJAJ-AUTO.NS - Close\n",
      "Processed BAJFINANCE.NS - Close\n",
      "Processed BAJAJFINSV.NS - Close\n",
      "Processed BPCL.NS - Close\n",
      "Processed BHARTIARTL.NS - Close\n",
      "Processed BRITANNIA.NS - Close\n",
      "Processed CIPLA.NS - Close\n",
      "Processed COALINDIA.NS - Close\n",
      "Processed DIVISLAB.NS - Close\n",
      "Processed DRREDDY.NS - Close\n",
      "Processed EICHERMOT.NS - Close\n",
      "Processed GRASIM.NS - Close\n",
      "Processed HCLTECH.NS - Close\n",
      "Processed HDFCBANK.NS - Close\n",
      "Processed HDFCLIFE.NS - Close\n",
      "Processed HEROMOTOCO.NS - Close\n",
      "Processed HINDALCO.NS - Close\n",
      "Processed HINDUNILVR.NS - Close\n",
      "Processed ICICIBANK.NS - Close\n",
      "Processed ITC.NS - Close\n",
      "Processed INDUSINDBK.NS - Close\n",
      "Processed INFY.NS - Close\n",
      "Processed JSWSTEEL.NS - Close\n",
      "Processed KOTAKBANK.NS - Close\n",
      "Processed LT.NS - Close\n",
      "Processed M&M.NS - Close\n",
      "Processed MARUTI.NS - Close\n",
      "Processed NESTLEIND.NS - Close\n",
      "Processed NTPC.NS - Close\n",
      "Processed ONGC.NS - Close\n",
      "Processed POWERGRID.NS - Close\n",
      "Processed RELIANCE.NS - Close\n",
      "Processed SBILIFE.NS - Close\n",
      "Processed SBIN.NS - Close\n",
      "Processed SUNPHARMA.NS - Close\n",
      "Processed TATAMOTORS.NS - Close\n",
      "Processed TATASTEEL.NS - Close\n",
      "Processed TCS.NS - Close\n",
      "Processed TECHM.NS - Close\n",
      "Processed TITAN.NS - Close\n",
      "Processed ULTRACEMCO.NS - Close\n",
      "Processed UPL.NS - Close\n",
      "Processed WIPRO.NS - Close\n",
      "Processed ADANIPORTS.NS - Volume\n",
      "Processed APOLLOHOSP.NS - Volume\n",
      "Processed ASIANPAINT.NS - Volume\n",
      "Processed AXISBANK.NS - Volume\n",
      "Processed BAJAJ-AUTO.NS - Volume\n",
      "Processed BAJFINANCE.NS - Volume\n",
      "Processed BAJAJFINSV.NS - Volume\n",
      "Processed BPCL.NS - Volume\n",
      "Processed BHARTIARTL.NS - Volume\n",
      "Processed BRITANNIA.NS - Volume\n",
      "Processed CIPLA.NS - Volume\n",
      "Processed COALINDIA.NS - Volume\n",
      "Processed DIVISLAB.NS - Volume\n",
      "Processed DRREDDY.NS - Volume\n",
      "Processed EICHERMOT.NS - Volume\n",
      "Processed GRASIM.NS - Volume\n",
      "Processed HCLTECH.NS - Volume\n",
      "Processed HDFCBANK.NS - Volume\n",
      "Processed HDFCLIFE.NS - Volume\n",
      "Processed HEROMOTOCO.NS - Volume\n",
      "Processed HINDALCO.NS - Volume\n",
      "Processed HINDUNILVR.NS - Volume\n",
      "Processed ICICIBANK.NS - Volume\n",
      "Processed ITC.NS - Volume\n",
      "Processed INDUSINDBK.NS - Volume\n",
      "Processed INFY.NS - Volume\n",
      "Processed JSWSTEEL.NS - Volume\n",
      "Processed KOTAKBANK.NS - Volume\n",
      "Processed LT.NS - Volume\n",
      "Processed M&M.NS - Volume\n",
      "Processed MARUTI.NS - Volume\n",
      "Processed NESTLEIND.NS - Volume\n",
      "Processed NTPC.NS - Volume\n",
      "Processed ONGC.NS - Volume\n",
      "Processed POWERGRID.NS - Volume\n",
      "Processed RELIANCE.NS - Volume\n",
      "Processed SBILIFE.NS - Volume\n",
      "Processed SBIN.NS - Volume\n",
      "Processed SUNPHARMA.NS - Volume\n",
      "Processed TATAMOTORS.NS - Volume\n",
      "Processed TATASTEEL.NS - Volume\n",
      "Processed TCS.NS - Volume\n",
      "Processed TECHM.NS - Volume\n",
      "Processed TITAN.NS - Volume\n",
      "Processed ULTRACEMCO.NS - Volume\n",
      "Processed UPL.NS - Volume\n",
      "Processed WIPRO.NS - Volume\n",
      "Processed ADANIPORTS.NS - Dividends\n",
      "Processed APOLLOHOSP.NS - Dividends\n",
      "Processed ASIANPAINT.NS - Dividends\n",
      "Processed AXISBANK.NS - Dividends\n",
      "Processed BAJAJ-AUTO.NS - Dividends\n",
      "Processed BAJFINANCE.NS - Dividends\n",
      "Processed BAJAJFINSV.NS - Dividends\n",
      "Processed BPCL.NS - Dividends\n",
      "Processed BHARTIARTL.NS - Dividends\n",
      "Processed BRITANNIA.NS - Dividends\n",
      "Processed CIPLA.NS - Dividends\n",
      "Processed COALINDIA.NS - Dividends\n",
      "Processed DIVISLAB.NS - Dividends\n",
      "Processed DRREDDY.NS - Dividends\n",
      "Processed EICHERMOT.NS - Dividends\n",
      "Processed GRASIM.NS - Dividends\n",
      "Processed HCLTECH.NS - Dividends\n",
      "Processed HDFCBANK.NS - Dividends\n",
      "Processed HDFCLIFE.NS - Dividends\n",
      "Processed HEROMOTOCO.NS - Dividends\n",
      "Processed HINDALCO.NS - Dividends\n",
      "Processed HINDUNILVR.NS - Dividends\n",
      "Processed ICICIBANK.NS - Dividends\n",
      "Processed ITC.NS - Dividends\n",
      "Processed INDUSINDBK.NS - Dividends\n",
      "Processed INFY.NS - Dividends\n",
      "Processed JSWSTEEL.NS - Dividends\n",
      "Processed KOTAKBANK.NS - Dividends\n",
      "Processed LT.NS - Dividends\n",
      "Processed M&M.NS - Dividends\n",
      "Processed MARUTI.NS - Dividends\n",
      "Processed NESTLEIND.NS - Dividends\n",
      "Processed NTPC.NS - Dividends\n",
      "Processed ONGC.NS - Dividends\n",
      "Processed POWERGRID.NS - Dividends\n",
      "Processed RELIANCE.NS - Dividends\n",
      "Processed SBILIFE.NS - Dividends\n",
      "Processed SBIN.NS - Dividends\n",
      "Processed SUNPHARMA.NS - Dividends\n",
      "Processed TATAMOTORS.NS - Dividends\n",
      "Processed TATASTEEL.NS - Dividends\n",
      "Processed TCS.NS - Dividends\n",
      "Processed TECHM.NS - Dividends\n",
      "Processed TITAN.NS - Dividends\n",
      "Processed ULTRACEMCO.NS - Dividends\n",
      "Processed UPL.NS - Dividends\n",
      "Processed WIPRO.NS - Dividends\n",
      "Processed ADANIPORTS.NS - Stock Splits\n",
      "Processed APOLLOHOSP.NS - Stock Splits\n",
      "Processed ASIANPAINT.NS - Stock Splits\n",
      "Processed AXISBANK.NS - Stock Splits\n",
      "Processed BAJAJ-AUTO.NS - Stock Splits\n",
      "Processed BAJFINANCE.NS - Stock Splits\n",
      "Processed BAJAJFINSV.NS - Stock Splits\n",
      "Processed BPCL.NS - Stock Splits\n",
      "Processed BHARTIARTL.NS - Stock Splits\n",
      "Processed BRITANNIA.NS - Stock Splits\n",
      "Processed CIPLA.NS - Stock Splits\n",
      "Processed COALINDIA.NS - Stock Splits\n",
      "Processed DIVISLAB.NS - Stock Splits\n",
      "Processed DRREDDY.NS - Stock Splits\n",
      "Processed EICHERMOT.NS - Stock Splits\n",
      "Processed GRASIM.NS - Stock Splits\n",
      "Processed HCLTECH.NS - Stock Splits\n",
      "Processed HDFCBANK.NS - Stock Splits\n",
      "Processed HDFCLIFE.NS - Stock Splits\n",
      "Processed HEROMOTOCO.NS - Stock Splits\n",
      "Processed HINDALCO.NS - Stock Splits\n",
      "Processed HINDUNILVR.NS - Stock Splits\n",
      "Processed ICICIBANK.NS - Stock Splits\n",
      "Processed ITC.NS - Stock Splits\n",
      "Processed INDUSINDBK.NS - Stock Splits\n",
      "Processed INFY.NS - Stock Splits\n",
      "Processed JSWSTEEL.NS - Stock Splits\n",
      "Processed KOTAKBANK.NS - Stock Splits\n",
      "Processed LT.NS - Stock Splits\n",
      "Processed M&M.NS - Stock Splits\n",
      "Processed MARUTI.NS - Stock Splits\n",
      "Processed NESTLEIND.NS - Stock Splits\n",
      "Processed NTPC.NS - Stock Splits\n",
      "Processed ONGC.NS - Stock Splits\n",
      "Processed POWERGRID.NS - Stock Splits\n",
      "Processed RELIANCE.NS - Stock Splits\n",
      "Processed SBILIFE.NS - Stock Splits\n",
      "Processed SBIN.NS - Stock Splits\n",
      "Processed SUNPHARMA.NS - Stock Splits\n",
      "Processed TATAMOTORS.NS - Stock Splits\n",
      "Processed TATASTEEL.NS - Stock Splits\n",
      "Processed TCS.NS - Stock Splits\n",
      "Processed TECHM.NS - Stock Splits\n",
      "Processed TITAN.NS - Stock Splits\n",
      "Processed ULTRACEMCO.NS - Stock Splits\n",
      "Processed UPL.NS - Stock Splits\n",
      "Processed WIPRO.NS - Stock Splits\n",
      "Data written to PostgreSQL database.\n"
     ]
    }
   ],
   "source": [
    "from app import app, db, bcrypt\n",
    "from models import User, Stock, Portfolio\n",
    "from flask import jsonify, request\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import time\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Nifty 50 company symbols (Yahoo Finance format)\n",
    "companyNamesArray = [\n",
    "    'ADANIPORTS.NS', 'APOLLOHOSP.NS', 'ASIANPAINT.NS', 'AXISBANK.NS', 'BAJAJ-AUTO.NS', 'BAJFINANCE.NS', 'BAJAJFINSV.NS',\n",
    "    'BPCL.NS', 'BHARTIARTL.NS', 'BRITANNIA.NS', 'CIPLA.NS', 'COALINDIA.NS', 'DIVISLAB.NS', 'DRREDDY.NS', 'EICHERMOT.NS',\n",
    "    'GRASIM.NS', 'HCLTECH.NS', 'HDFCBANK.NS', 'HDFCLIFE.NS', 'HEROMOTOCO.NS', 'HINDALCO.NS', 'HINDUNILVR.NS',\n",
    "    'ICICIBANK.NS', 'ITC.NS', 'INDUSINDBK.NS', 'INFY.NS', 'JSWSTEEL.NS', 'KOTAKBANK.NS', 'LT.NS', 'M&M.NS',\n",
    "    'MARUTI.NS', 'NESTLEIND.NS', 'NTPC.NS', 'ONGC.NS', 'POWERGRID.NS', 'RELIANCE.NS', 'SBILIFE.NS', 'SBIN.NS',\n",
    "    'SUNPHARMA.NS', 'TATAMOTORS.NS', 'TATASTEEL.NS', 'TCS.NS', 'TECHM.NS', 'TITAN.NS', 'ULTRACEMCO.NS', 'UPL.NS', 'WIPRO.NS'\n",
    "]\n",
    "\n",
    "# Download data in smaller batches with proper error handling\n",
    "all_data = []\n",
    "batch_size = 15  # Reduced batch size\n",
    "max_retries = 3\n",
    "\n",
    "for i in range(0, len(companyNamesArray), batch_size):\n",
    "    batch = companyNamesArray[i:i+batch_size]\n",
    "    tickers = \" \".join(batch)\n",
    "    \n",
    "    for retry in range(max_retries):\n",
    "        try:\n",
    "            ms = yf.Tickers(tickers)\n",
    "            data = ms.history(period=\"max\")\n",
    "            if not data.empty:\n",
    "                all_data.append(data)\n",
    "                print(f\"Downloaded: {batch}\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {retry + 1} failed for batch {batch}: {e}\")\n",
    "            if retry == max_retries - 1:\n",
    "                print(f\"Skipping batch {batch} after {max_retries} attempts\")\n",
    "            time.sleep(10 * (retry + 1))  # Exponential backoff\n",
    "\n",
    "# Process data in chunks\n",
    "chunk_size = 100000  # Adjust based on your system's memory\n",
    "\n",
    "# Combine and process data\n",
    "try:\n",
    "    stockData_22 = pd.concat(all_data)\n",
    "    stockData_22 = stockData_22.loc[:, (['Close','Volume','Dividends','Stock Splits'], companyNamesArray)]\n",
    "    stockData_22.columns = stockData_22.columns.map(lambda x: f\"{x[0]}_{x[1]}\")\n",
    "    stockData_22 = stockData_22.reset_index()\n",
    "    \n",
    "    # Create metrics and companies DataFrames (these are usually small)\n",
    "    metrics = ['Close','Volume', 'Dividends', 'Stock Splits']\n",
    "    metrics_df = pd.DataFrame({'metric': metrics})\n",
    "    metrics_df['Metric_ID'] = metrics_df.index + 1\n",
    "    \n",
    "    companies_df = pd.DataFrame({'company': companyNamesArray})\n",
    "    companies_df['Company_ID'] = companies_df.index + 1\n",
    "\n",
    "    # Connect to PostgreSQL\n",
    "    load_dotenv()\n",
    "    \n",
    "    # Try to create database (ignore if exists)\n",
    "    engine = create_engine(f\"postgresql://{os.getenv('POSTGRES_USER')}:{os.getenv('POSTGRES_PASSWORD')}@localhost:5432/postgres\")\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            conn.execution_options(isolation_level=\"AUTOCOMMIT\").execute(\n",
    "                text(f\"CREATE DATABASE {os.getenv('POSTGRES_DB')}\")\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"Note: {e}\")  # Database might already exist\n",
    "\n",
    "    # Connect to the target database\n",
    "    pg_url = f\"postgresql://{os.getenv('POSTGRES_USER')}:{os.getenv('POSTGRES_PASSWORD')}@localhost:5432/{os.getenv('POSTGRES_DB')}\"\n",
    "    engine = create_engine(pg_url)\n",
    "\n",
    "    # Write small tables first\n",
    "    metrics_df.to_sql('Metrics', engine, if_exists='replace', index=False)\n",
    "    companies_df.to_sql('Companies', engine, if_exists='replace', index=False)\n",
    "\n",
    "    # Process and write the large data table in chunks\n",
    "    for metric in metrics:\n",
    "        for company in companyNamesArray:\n",
    "            column_name = f\"{metric}_{company}\"\n",
    "            if column_name in stockData_22.columns:\n",
    "                # Get company_id and metric_id\n",
    "                company_id = companies_df[companies_df['company'] == company]['Company_ID'].iloc[0]\n",
    "                metric_id = metrics_df[metrics_df['metric'] == metric]['Metric_ID'].iloc[0]\n",
    "                \n",
    "                # Create chunk of data for this company/metric\n",
    "                temp_df = pd.DataFrame({\n",
    "                    'Date': stockData_22['Date'],\n",
    "                    'Company_ID': company_id,\n",
    "                    'Metric_ID': metric_id,\n",
    "                    'value': stockData_22[column_name]\n",
    "                })\n",
    "                \n",
    "                # Write to database in chunks\n",
    "                temp_df.to_sql('Data', engine, if_exists='append', index=False, \n",
    "                             method='multi', chunksize=10000)\n",
    "                \n",
    "                print(f\"Processed {company} - {metric}\")\n",
    "\n",
    "    print(\"Data written to PostgreSQL database.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during processing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04172edf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "investmentapp",
   "language": "python",
   "name": "investmentapp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
